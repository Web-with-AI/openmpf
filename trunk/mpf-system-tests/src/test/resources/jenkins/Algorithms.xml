<?xml version="1.0" encoding="UTF-8"?>
<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ~ NOTICE                                                                    ~
  ~                                                                           ~
  ~ This software (or technical data) was produced for the U.S. Government    ~
  ~ under contract, and is subject to the Rights in Data-General Clause       ~
  ~ 52.227-14, Alt. IV (DEC 2007).                                            ~
  ~                                                                           ~
  ~ Copyright 2016 The MITRE Corporation. All Rights Reserved.                ~
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

<!--~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  ~ Copyright 2016 The MITRE Corporation                                      ~
  ~                                                                           ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");           ~
  ~ you may not use this file except in compliance with the License.          ~
  ~ You may obtain a copy of the License at                                   ~
  ~                                                                           ~
  ~    http://www.apache.org/licenses/LICENSE-2.0                             ~
  ~                                                                           ~
  ~ Unless required by applicable law or agreed to in writing, software       ~
  ~ distributed under the License is distributed on an "AS IS" BASIS,         ~
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  ~
  ~ See the License for the specific language governing permissions and       ~
  ~ limitations under the License.                                            ~
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~-->

<algorithms>
    <!--

    #############
    # DETECTION #
    #############

    -->

    <algorithm name="FACECV" actionType="DETECTION">
        <description>Detects faces in images and videos.</description>
        <provides>
            <properties>
                <property type="INT" name="TARGET_SEGMENT_LENGTH" propertiesKey="detection.segment.target.length">
                    <description>In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_SEGMENT_LENGTH" propertiesKey="detection.segment.minimum.length">
                    <description>In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_GAP_BETWEEN_SEGMENTS" propertiesKey="detection.segment.minimum.gap">
                    <description>In the context of videos, the minimum number of frames or time between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property name="MIN_FACE_SIZE" type="INT" defaultValue="48">
                    <description>Minimum x and y pixel size passed to the opencv face detector</description>
                </property>
                <property name="MAX_FEATURE" type="INT" defaultValue="250">
                    <description>Max feature points calculated when detecting features on the face</description>
                </property>
                <property name="MIN_INIT_POINT_COUNT" type="INT" defaultValue="45">
                    <description>Minimum points needed by feature detector within detected face bounding box</description>
                </property>
                <property name="MIN_POINT_PERCENT" type="FLOAT" defaultValue="0.70">
                    <description>Min point percentage when comparing current feature points to initial feature points - when the ratio drops below 0.70 the track could be lost</description>
                </property>
                <property name="MIN_INITIAL_CONFIDENCE" type="FLOAT" defaultValue="10">
                    <description>Minimum face detection confidence value needed to start a track, must be greater than 0</description>
                </property>
                <property name="MAX_OPTICAL_FLOW_ERROR" type="FLOAT" defaultValue="4.7">
                    <description>UNUSED option to ignore certain points that do not meet a certain quality when using the calcopticalflow alg</description>
                </property>
                <property name="VERBOSE" type="INT" defaultValue="0">
                    <description>VERBOSE = 1: print settings and detection results and VERBOSE = 0: no debugging output</description>
                </property>
                <property name="FRAME_INTERVAL" type="INT" defaultValue="1">
                    <description>Controls whether the component performs detection on every frame in the video segment, or skips some frames at a regular interval. Must be greater than or equal to 0. If the frame_interval is set to 0 or 1, a frame_interval of 1 will be used, so that detections are performed on every frame. For a frame interval N > 1, every N-1 frames will be skipped.</description>
                </property>
                <property type="BOOLEAN" name="MERGE_TRACKS" defaultValue="false">
                    <description>When set to true, the detection response handler will merge tracks spanning segment boundaries.</description>
                </property>
                <property type="DOUBLE" name="CONFIDENCE_THRESHOLD" defaultValue="-2">
                    <description>The minimum confidence score which must be met or exceeded. Detections below this threshold are silently discarded.</description>
                </property>
                <property type="BOOLEAN" name="SEARCH_REGION_ENABLE_DETECTION" defaultValue="false">
                    <description>Enable cropping. Rotation is performed before cropping. The region of interest coordinates relate to the rotated media.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media will be used.</description>
                </property>
                <property type="INT" name="ROTATION" defaultValue="0">
                    <description>Specifies the number of degrees to rotate the image. The rotation is clockwise. Only 90, 180 and 270 degrees are supported.</description>
                </property>
                <property type="BOOLEAN" name="HORIZONTAL_FLIP" defaultValue="false">
                    <description>Specifies whether or not the original media is flipped. Rotation occurs before flipping.</description>
                </property>
                <property type="BOOLEAN" name="AUTO_ROTATE" defaultValue="false">
                    <description>Specifies whether not to rotate media based on EXIF data.</description>
                </property>
                <property type="BOOLEAN" name="AUTO_FLIP" defaultValue="false">
                    <description>Specifies whether or not to flip media based on EXIF data.</description>
                </property>
            </properties>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_FACE" />
                <state name="DETECTION_FACE_OCV" />
            </states>
        </provides>
    </algorithm>
    <algorithm name="DLIB" actionType="DETECTION">
        <description>Dlib Face Detection and Tracking</description>
        <provides>
            <properties>
                <property name="VERBOSE" type="INT" defaultValue="0">
                    <description>VERBOSE = 0: no debugging output and VERBOSE = 1: print settings and detection results.</description>
                </property>
                <property name="MIN_DETECTION_CONFIDENCE" type="DOUBLE" defaultValue="0.1">
                    <description>This is the minimum dlib object detection confidence needed to start a new track.</description>
                </property>
                <property name="MAX_INTERSECTION_OVERLAP_AREA_PCT" type="FLOAT" defaultValue="0.2">
                    <description>UNUSED (not currently allowing any overlap) - the maximum allowable overlap rate between a new detection rect and any existing track rects.</description>
                </property>
                <property name="MIN_OBJECT_DETECTIONS_COUNT" type="INT" defaultValue="3">
                    <description>The minumum amount of frame locations required to save a track.</description>
                </property>
                <property name="MIN_TRACK_OBJECT_SIMILARITY_VALUE" type="FLOAT" defaultValue="0.6">
                    <description>The minimum amount of similarity required by a detection to be matched with an existing track.</description>
                </property>
                <property name="MIN_UPDATE_CORRELATION" type="DOUBLE" defaultValue="6.5">
                    <description>The minimum amount of correlation between frames needed to continue tracking.</description>
                </property>
                <property name="FRAME_INTERVAL" type="INT" defaultValue="1">
                    <description>Controls whether the component performs detection on every frame in the video segment, or skips some frames at a regular interval. Must be greater than or equal to 0. If the frame_interval is set to 0 or 1, a frame_interval of 1 will be used, so that detections are performed on every frame. For a frame interval N &gt; 1, every N-1 frames will be skipped.</description>
                </property>
                <property type="BOOLEAN" name="SEARCH_REGION_ENABLE_DETECTION" defaultValue="false">
                    <description>Enable cropping. Rotation is performed before cropping. The region of interest coordinates relate to the rotated media.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media. will be used.</description>
                </property>
                <property type="INT" name="ROTATION" defaultValue="0">
                    <description> Specifies the number of degrees to rotate the image. The rotation is clockwise. Only 90, 180 and 270 degrees are supported. </description>
                </property>
                <property type="BOOLEAN" name="HORIZONTAL_FLIP" defaultValue="false">
                    <description> Specifies whether or not the original media is flipped. Rotation occurs before flipping. </description>
                </property>
            </properties>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_FACE" />
                <state name="DETECTION_FACE_DLIB" />
            </states>
        </provides>
        <requires>
            <state-refs />
        </requires>
    </algorithm>
    <algorithm name="MOG" actionType="DETECTION">
        <description>Detects motion in videos.</description>
        <provides>
            <properties>
                <property type="INT" name="TARGET_SEGMENT_LENGTH" propertiesKey="detection.segment.target.length">
                    <description>In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_SEGMENT_LENGTH" propertiesKey="detection.segment.minimum.length">
                    <description>In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="FRAME_INTERVAL" defaultValue="1">
                    <description>Instructs the algorithm to skip (FRAME_INTERVAL - 1) frames in videos. Has no effect for images. Value must be greater than or equal to 1.</description>
                </property>
                <property type="INT" name="MIN_GAP_BETWEEN_SEGMENTS" propertiesKey="detection.segment.minimum.gap">
                    <description>In the context of videos, the minimum number of frames or time between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="HISTORY_LENGTH" defaultValue="500">
                    <description>The number of previous frames to use as the background image.</description>
                </property>
                <property type="INT" name="VAR_THRESHOLD" defaultValue="16">
                    <description>Threshold on the squared Mahalanobis distance to decide whether it is well described by the background model. This parameter does not affect the background update. A typical value could be 4 sigma, that is, varThreshold=4*4=16; (definition from OpenCV).</description>
                </property>
                <property type="BOOLEAN" name="BACKGROUND_SHADOW_DETECTION" defaultValue="true">
                    <description>Parameter defining whether shadow detection should be enabled (definition from OpenCV).</description>
                </property>
                <property name="MAXIMUM_FRAME_WIDTH" type="INT" defaultValue="128">
                    <description>Maximum width of the frame passed to MOG2. The frame will be downsampled until it is at or below the value. Smaller frames result in increased speed of MOG2. The frame original aspect ratio is maintained.</description>
                </property>
                <property name="MAXIMUM_FRAME_HEIGHT" type="INT" defaultValue="128">
                    <description>Maximum height of the frame passed to MOG2. The frame will be downsampled until it is at or below the value. Smaller frames result in increased speed of MOG2. The frame's original aspect ratio is maintained.</description>
                </property>
                <property name="MIN_RECT_WIDTH" type="INT" defaultValue="16">
                    <description>Minimum width of detected motion in the original frame.</description>
                </property>
                <property name="MIN_RECT_HEIGHT" type="INT" defaultValue="16">
                    <description>Minimum height of detected motion in the original frame.</description>
                </property>
                <property name="ERODE_ANCHOR_X" type="INT" defaultValue="-1">
                    <description>X position of the anchor within the element; -1 means that the anchor is at the element x center (definition from OpenCV).</description>
                </property>
                <property name="ERODE_ANCHOR_Y" type="INT" defaultValue="-1">
                    <description>Y position of the anchor within the element; -1 means that the anchor is at the element y center (definition from OpenCV).</description>
                </property>
                <property name="ERODE_ITERATIONS" type="INT" defaultValue="1">
                    <description>The number of times erosion is applied.</description>
                </property>
                <property name="DILATE_ANCHOR_X" type="INT" defaultValue="-1">
                    <description>X position of the anchor within the element; -1 means that the anchor is at the element x center (definition from OpenCV).</description>
                </property>
                <property name="DILATE_ANCHOR_Y" type="INT" defaultValue="-1">
                    <description>Y position of the anchor within the element; -1 means that the anchor is at the element y center (definition from OpenCV).</description>
                </property>
                <property name="DILATE_ITERATIONS" type="INT" defaultValue="1">
                    <description>The number of times dilation is applied.</description>
                </property>
                <property name="MEDIAN_BLUR_K_SIZE" type="INT" defaultValue="3">
                    <description>Aperture linear size; it must be odd and greater than 1(definition from OpenCV).</description>
                </property>
                <property name="GROUP_RECTANGLES_GROUP_THRESHOLD" type="INT" defaultValue="1">
                    <description>Minimum possible number of rectangles minus 1. The threshold is used in a group of rectangles to retain it (definition from OpenCV).</description>
                </property>
                <property name="GROUP_RECTANGLES_EPS" type="DOUBLE" defaultValue="0.2">
                    <description>Relative difference between sides of the rectangles to merge them into a group (definition from OpenCV).</description>
                </property>
                <property name="USE_MOTION_TRACKING" type="INT" defaultValue="0">
                    <description>0: Do not use tracking algorithm (old method). 1: Use STRUCK tracking.</description>
                </property>
                <property name="TRACKING_MAX_OBJECT_PERCENTAGE" type="DOUBLE" defaultValue="0.9">
                    <description>Max size of track as percentage of frame.</description>
                </property>
                <property name="TRACKING_THRESHOLD" type="DOUBLE" defaultValue="-1">
                    <description>The threshold for STRUCK when determining if a track should stop.</description>
                </property>
                <property name="USE_PREPROCESSOR" type="INT" defaultValue="0">
                    <description>Enables the use of motion as a preprocessor. Only will return if motion is in frame. Overrides USE_MOTION_TRACKING.</description>
                </property>
                <property name="VERBOSE" type="INT" defaultValue="0">
                    <description>0: no debugging output 1: log all track results.</description>
                </property>
                <property type="BOOLEAN" name="EXTRACT_TRACK_DATA_FROM_MEDIA" defaultValue="true">
                    <description>When set to true, track frames will be extracted from images and videos.</description>
                </property>
                <property type="BOOLEAN" name="MERGE_TRACKS" defaultValue="false">
                    <description>When set to true, the detection response handler will merge tracks spanning segment boundaries.</description>
                </property>
                <property type="BOOLEAN" name="SEARCH_REGION_ENABLE_DETECTION" defaultValue="false">
                    <description>Enable cropping. Rotation is performed before cropping. The region of interest coordinates relate to the rotated media.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media. will be used.</description>
                </property>
                <property type="INT" name="ROTATION" defaultValue="0">
                    <description> Specifies the number of degrees to rotate the image. The rotation is clockwise. Only 90, 180 and 270 degrees are supported. </description>
                </property>
                <property type="BOOLEAN" name="HORIZONTAL_FLIP" defaultValue="false">
                    <description> Specifies whether or not the original media is flipped. Rotation occurs before flipping. </description>
                </property>
            </properties>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_MOTION" />
                <state name="DETECTION_MOTION_MOG" />
            </states>
        </provides>
    </algorithm>
    <algorithm name="OALPR" actionType="DETECTION">
        <description>Detects the text on license plates in images and videos.</description>
        <provides>
            <properties>
                <property type="INT" name="TARGET_SEGMENT_LENGTH" propertiesKey="detection.segment.target.length">
                    <description>In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_SEGMENT_LENGTH" propertiesKey="detection.segment.minimum.length">
                    <description>In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_GAP_BETWEEN_SEGMENTS" propertiesKey="detection.segment.minimum.gap">
                    <description>In the context of videos, the minimum number of frames or time between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="FRAME_INTERVAL" defaultValue="1">
                    <description>Instructs the algorithm to skip (FRAME_INTERVAL - 1) frames in videos. Has no effect for images. Value must be greater than or equal to 1.</description>
                </property>
                <property type="BOOLEAN" name="EXTRACT_TRACK_DATA_FROM_MEDIA" defaultValue="true">
                    <description>When set to true, track frames will be extracted from images and videos.</description>
                </property>
                <property type="BOOLEAN" name="MERGE_TRACKS" defaultValue="false">
                    <description>When set to true, the detection response handler will merge tracks spanning segment boundaries.</description>
                </property>
                <property type="DOUBLE" name="MIN_OVERLAP" propertiesKey="detection.track.overlap.threshold">
                    <description>In the context of videos, the minimum overlap between detection bounding boxes for adjacent segments to be considered continuous. Value is expected to be between 0 and 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="DOUBLE" name="CONFIDENCE_THRESHOLD" defaultValue="-2">
                    <description>Removes all text that has a confidence score below the given value.</description>
                </property>
                <property type="BOOLEAN" name="SEARCH_REGION_ENABLE_DETECTION" defaultValue="false">
                    <description>Enable cropping. Rotation is performed before cropping. The region of interest coordinates relate to the rotated media.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media. will be used.</description>
                </property>
                <property type="INT" name="ROTATION" defaultValue="0">
                    <description> Specifies the number of degrees to rotate the image. The rotation is clockwise. Only 90, 180 and 270 degrees are supported. </description>
                </property>
                <property type="BOOLEAN" name="HORIZONTAL_FLIP" defaultValue="false">
                    <description> Specifies whether or not the original media is flipped. Rotation occurs before flipping. </description>
                </property>
            </properties>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_TEXT" />
                <state name="DETECTION_TEXT_OALPR" />
            </states>
        </provides>
    </algorithm>
    <algorithm name="PERSONCV" actionType="DETECTION">
        <description>Detects people in images and videos.</description>
        <provides>
            <properties>
                <property type="INT" name="TARGET_SEGMENT_LENGTH" propertiesKey="detection.segment.target.length">
                    <description>In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_SEGMENT_LENGTH" propertiesKey="detection.segment.minimum.length">
                    <description>In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_GAP_BETWEEN_SEGMENTS" propertiesKey="detection.segment.minimum.gap">
                    <description>In the context of videos, the minimum number of frames or time between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="FRAME_INTERVAL" defaultValue="1">
                    <description>Instructs the algorithm skip (FRAME_INTERVAL - 1) frames in videos. Has no effect for images. Value must be greater than or equal to 1.</description>
                </property>
                <property type="BOOLEAN" name="EXTRACT_TRACK_DATA_FROM_MEDIA" defaultValue="true">
                    <description>When set to true, track frames will be extracted from images and videos.</description>
                </property>
                <property type="BOOLEAN" name="MERGE_TRACKS" defaultValue="false">
                    <description>When set to true, the detection response handler will merge tracks spanning segment boundaries.</description>
                </property>
                <property type="DOUBLE" name="MIN_OVERLAP" propertiesKey="detection.track.overlap.threshold">
                    <description>In the context of videos, the minimum overlap between detection bounding boxes for adjacent segments to be considered continuous. Value is expected to be between 0 and 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="BOOLEAN" name="SEARCH_REGION_ENABLE_DETECTION" defaultValue="false">
                    <description>Enable cropping. Rotation is performed before cropping. The region of interest coordinates relate to the rotated media.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_TOP_LEFT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for top left corner of cropped frame. If negative, 0 will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION" defaultValue="-1">
                    <description>X coordinate for bottom right corner of cropped frame. If negative, bottom right X of input media will be used.</description>
                </property>
                <property type="INT" name="SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION" defaultValue="-1">
                    <description>Y coordinate for bottom right corner of cropped frame. If negative, bottom right Y of input media. will be used.</description>
                </property>
                <property type="INT" name="ROTATION" defaultValue="0">
                    <description> Specifies the number of degrees to rotate the image. The rotation is clockwise. Only 90, 180 and 270 degrees are supported. </description>
                </property>
                <property type="BOOLEAN" name="HORIZONTAL_FLIP" defaultValue="false">
                    <description> Specifies whether or not the original media is flipped. Rotation occurs before flipping. </description>
                </property>
            </properties>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_PERSON" />
                <state name="DETECTION_PERSON_OCV" />
            </states>
        </provides>
    </algorithm>
    <algorithm name="SPHINX" actionType="DETECTION">
        <description>Detects and transcribes English language speech in audio and video files.</description>
        <provides>
            <states>
                <state name="DETECTION" />
                <state name="DETECTION_SPEECH" />
                <state name="DETECTION_SPEECH_SPHINX" />
            </states>
            <properties>
                <property type="INT" name="TARGET_SEGMENT_LENGTH" propertiesKey="detection.segment.target.length">
                    <description>In the context of videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_SEGMENT_LENGTH" propertiesKey="detection.segment.minimum.length">
                    <description>In the context of videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="MIN_GAP_BETWEEN_SEGMENTS" propertiesKey="detection.segment.minimum.gap">
                    <description>In the context of videos, the minimum number of frames or time between segments which are not adjacent. Value must be greater than or equal to 1. Default value is defined by the MPF properties file.</description>
                </property>
                <property type="INT" name="FRAME_INTERVAL" defaultValue="1">
                    <description>Instructs the algorithm skip (FRAME_INTERVAL - 1) frames in videos. Has no effect for images. Value must be greater than or equal to 1.</description>
                </property>
                <property type="BOOLEAN" name="EXTRACT_TRACK_DATA_FROM_MEDIA" defaultValue="true">
                    <description>When set to true, track frames will be extracted from images and videos.</description>
                </property>
                <property type="BOOLEAN" name="MERGE_TRACKS" defaultValue="false">
                    <description>When set to true, the detection response handler will merge tracks spanning segment boundaries.</description>
                </property>
            </properties>
        </provides>
    </algorithm>

    <!--

    ##########
    # MARKUP #
    ##########

    -->

    <algorithm name="MARKUPCV" actionType="MARKUP">
        <description>Marks up any objects which were detected in the last detection task of a pipeline. Does not support audio files (e.g., MP3, WAV, etc.).</description>
        <requires>
            <state-refs>
                <state-ref name="DETECTION" />
            </state-refs>
        </requires>
    </algorithm>


</algorithms>
